{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test/val splits + balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "directory = r\"D:\\Sync\\research\\tree_species_estimation\\tree_dataset\\rmf\\processed\"\n",
    "eval_folders = [\"labels\", \"rmf_spl_climate\", \"rmf_imagery_climate\", \"rmf_phenology\", \\\n",
    "    \"rmf_aster_aspect\", \"rmf_aster_slope\", \"rmf_aster_topo\", \"rmf_aster_trasp\", \"rmf_aster_twi\", \\\n",
    "    \"rmf_spl_trasp\", \"rmf_spl_aspect\", \"rmf_spl_dem\", \"rmf_spl_slope\", \"rmf_spl_twi\"]\n",
    "resolutions = [10, 20]\n",
    "for resolution in resolutions:\n",
    "    ref_folder = os.path.join(directory, f'{resolution}m', \"rmf_s2\", \"fall\", \"tiles_128\")\n",
    "    files = [file for file in os.listdir(ref_folder) if file.endswith(\".tif\")]\n",
    "    for eval_folder in tqdm(eval_folders, leave=False):\n",
    "        folder = os.path.join(directory, f'{resolution}m', eval_folder, \"tiles_128\")\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            if filename not in files and os.path.isfile(file_path):\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_gen import get_tile_names_from_folder, load_raster_data_from_tiles, iterative_split, save_tile_names\n",
    "# Generate dataset splits\n",
    "resolutions = [10, 20]\n",
    "directory = r\"D:\\Sync\\research\\tree_species_estimation\\tree_dataset\\rmf\\processed\"\n",
    "for resolution in resolutions:\n",
    "    input_folder = os.path.join(directory, f\"{resolution}m\", \"labels\", \"tiles_128\")\n",
    "    output_folder = os.path.join(directory, f\"{resolution}m\", \"dataset\")\n",
    "\n",
    "    # Step 1: Get tile names from the input folder\n",
    "    tile_names = get_tile_names_from_folder(input_folder)\n",
    "\n",
    "    # Step 2: Load the actual raster data from tiles\n",
    "    raster_data = load_raster_data_from_tiles(input_folder, tile_names)\n",
    "\n",
    "    # Step 3: Perform the iterative split\n",
    "    train_indices, val_indices, test_indices = iterative_split(raster_data)\n",
    "\n",
    "    # Step 4: Save the tile names into .txt files\n",
    "    save_tile_names(tile_names, train_indices, val_indices, test_indices, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo import gdalconst\n",
    "import os\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "import fiona\n",
    "from ops.ops import load_json\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from osgeo import gdal_array\n",
    "from skimage.morphology import disk, dilation, erosion\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: \n",
    "https://github.com/klwalker-sb/burntfields_punjab\n",
    "\n",
    "https://github.com/aime-valentin/tree_species_predictions/tree/master\n",
    "\n",
    "https://github.com/swcoughlan/seaweed-classification\n",
    "\n",
    "https://github.com/MitaliBhurani/Delineating-urban-areas-from-satellite-imagery/blob/master/Sentinel_imbalaced_moradabad_cv.ipynb\n",
    "\n",
    "https://github.com/ML-MachineLearning/randomforest-GA/blob/master/random_forest.ipynb\n",
    "\n",
    "https://github.com/AgataKisel/imagery_classification-/blob/main/random_forest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random Forest\n",
    "\n",
    "ref: https://github.com/shelleygoel/sentinel2-land-cover-classifier/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Key Points:\n",
    "  - X (Features): Sentinel imagery tiles stored in s2/tiles_128/ (each tile has 12 bands, size 128x128).\n",
    "  - Y (Labels): The species composition tiles stored in labels/tiles_128/ (each tile has 9 bands, size 128x128). The target for each pixel is a 9-element vector representing species proportions.\n",
    "  - Train/Validation/Test Splits: The tiles to use for training, validation, and testing are specified in train.txt, validation.txt, and test.txt.\n",
    "- Step-by-Step Implementation:\n",
    "  - Loading Data: We'll read all 1060 tiles from the directories for both input (X) and target (Y).\n",
    "  - Random Forest: We'll use RandomForestRegressor to fit the data.\n",
    "  - Training/Validation/Test Splits: These splits are defined by the .txt files.\n",
    "  - Pixel-Wise Classification: The model will predict the species proportions for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:57<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of labels: (6553600, 9)\n",
      "shape of labels: (6553600, 9)\n",
      "loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of labels: (1638400, 9)\n",
      "shape of labels: (1638400, 9)\n",
      "start training...\n",
      "validating...\n",
      "Validation Mean Squared Error: 0.15307438335351384\n",
      "Validation R2 Score: 0.101579939498347\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to load tiles (X) and labels (Y)\n",
    "def load_tile_data(tile_names, tiles_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Load the imagery (X) and label (Y) data for the given tile names.\n",
    "\n",
    "    Args:\n",
    "        tile_names (list): List of tile names to load.\n",
    "        tiles_dir (str): Directory containing the Sentinel imagery (X).\n",
    "        labels_dir (str): Directory containing the species composition labels (Y).\n",
    "\n",
    "    Returns:\n",
    "        X (np.array): Flattened feature array (pixels x 12).\n",
    "        Y (np.array): Flattened label array (pixels x 9).\n",
    "    \"\"\"\n",
    "    X_list, Y_list = [], []\n",
    "    print(\"loading data...\")\n",
    "    for tile_name in tqdm(tile_names):\n",
    "        # Define paths for the input and label tiles\n",
    "        input_tile_path = os.path.join(tiles_dir, tile_name)\n",
    "        label_tile_path = os.path.join(labels_dir, tile_name)\n",
    "        \n",
    "        # Load input (12 bands) and label (9 bands) tiles\n",
    "        with rasterio.open(input_tile_path) as src_x:\n",
    "            X = src_x.read()  # Shape: (12, 128, 128)\n",
    "\n",
    "        with rasterio.open(label_tile_path) as src_y:\n",
    "            Y = src_y.read()  # Shape: (9, 128, 128)\n",
    "\n",
    "        # Reshape to (num_pixels, num_bands)\n",
    "        X_flat = X.reshape(X.shape[0], -1).T  # Shape: (num_pixels, 12)\n",
    "        Y_flat = Y.reshape(Y.shape[0], -1).T  # Shape: (num_pixels, 9)\n",
    "\n",
    "        # Append to lists\n",
    "        X_list.append(X_flat)\n",
    "        Y_list.append(Y_flat)\n",
    "    \n",
    "    # Concatenate all tiles into a single array\n",
    "    X_all = np.vstack(X_list)\n",
    "    print(f\"shape of labels: {X_all.shape}\")\n",
    "    Y_all = np.vstack(Y_list)\n",
    "    print(f\"shape of labels: {Y_all.shape}\")\n",
    "    \n",
    "    return X_all, Y_all\n",
    "\n",
    "# Function to read the train/validation/test splits\n",
    "def load_split(file_path):\n",
    "    \"\"\"\n",
    "    Load the tile names from the train/validation/test split files.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the split .txt file.\n",
    "\n",
    "    Returns:\n",
    "        tile_names (list): List of tile names in the split.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        tile_names = file.read().splitlines()\n",
    "    return tile_names\n",
    "\n",
    "# Set up directories\n",
    "directory = f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/20m'\n",
    "tiles_dir = os.path.join(directory, \"rmf_s2\", \"summer\", \"tiles_128\")  # Directory for X\n",
    "labels_dir = os.path.join(directory, \"labels\", \"tiles_128\")  # Directory for Y\n",
    "\n",
    "# Load train/validation/test splits\n",
    "train_tile_names = load_split(os.path.join(directory, 'dataset', 'train_tiles.txt'))[:400]\n",
    "val_tile_names = load_split(os.path.join(directory, 'dataset', 'val_tiles.txt'))[:100]\n",
    "\n",
    "# Load the training data\n",
    "X_train, Y_train = load_tile_data(train_tile_names, tiles_dir, labels_dir)\n",
    "\n",
    "# Load the validation data (optional, but useful for hyperparameter tuning)\n",
    "X_val, Y_val = load_tile_data(val_tile_names, tiles_dir, labels_dir)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "print(\"start training...\")\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "print(\"validating...\")\n",
    "Y_val_pred = rf.predict(X_val)\n",
    "val_mse = mean_squared_error(Y_val, Y_val_pred)\n",
    "val_r2 = r2_score(Y_val, Y_val_pred)\n",
    "print(f\"Validation Mean Squared Error: {val_mse}\")\n",
    "print(f\"Validation R2 Score: {val_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as random_forest_model.joblib\n",
      "loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [00:57<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of labels: (2605056, 9)\n",
      "shape of labels: (2605056, 9)\n",
      "Test Mean Squared Error with loaded model: 0.14655285462882345\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# After training the model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'random_forest_model.joblib'\n",
    "joblib.dump(rf, model_filename)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_rf = joblib.load(model_filename)\n",
    "\n",
    "# Load the testing data (for final evaluation)\n",
    "test_tile_names = load_split(os.path.join(directory, 'dataset', 'test_tiles.txt'))\n",
    "X_test, Y_test = load_tile_data(test_tile_names, tiles_dir, labels_dir)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "Y_test_pred = loaded_rf.predict(X_test)\n",
    "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "print(f\"Test Mean Squared Error with loaded model: {test_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LUCinSA_helpers\n",
    "Helper functions and notebooks to interact with data on High-Performance Computing environment, designed to be used in conjunction with processing guide for remote sensing projects on Land-Use Change in Latin America:\n",
    "\n",
    "https://github.com/klwalker-sb/LUCinSA_helpers/tree/master\n",
    "\n",
    "https://klwalker-sb.github.io/LUCinLA_stac/Downloading.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/PratyushTripathy/Landsat-Classification-Using-Convolution-Neural-Network/tree/master\n",
    "\n",
    "https://github.com/weecology/DeepTreeAttention/blob/main/README.md (attention + pylighting fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pylighting - UNET code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TreeSpeciesDataModule\n",
    "\n",
    "              ↓\n",
    " (inputs, targets, masks)  ← from DataLoader\n",
    "\n",
    "               ↓\n",
    " Training Loop\n",
    "\n",
    "              ↓\n",
    " MaskedMSELoss(outputs, targets, masks)\n",
    " \n",
    "              ↓\n",
    " Backpropagation (only for valid pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "import os\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Masked MSE Loss\n",
    "class MaskedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, targets, mask):\n",
    "        \"\"\"\n",
    "        Custom MSE loss function that ignores NoData pixels.\n",
    "\n",
    "        Args:\n",
    "        - outputs: Predicted values (batch_size, num_channels, H, W)\n",
    "        - targets: Ground truth values (batch_size, num_channels, H, W)\n",
    "        - mask: Boolean mask indicating NoData pixels (batch_size, H, W)\n",
    "\n",
    "        Returns:\n",
    "        - loss: Mean squared error computed only for valid pixels.\n",
    "        \"\"\"\n",
    "        # Expand mask to have the same number of channels as outputs and targets\n",
    "        expanded_mask = mask.unsqueeze(1).expand_as(outputs)  # Shape: (batch_size, num_channels, H, W)\n",
    "        \n",
    "        # Compute squared difference between outputs and targets\n",
    "        diff = (outputs - targets) ** 2\n",
    "\n",
    "        # Zero out contributions from NoData pixels (where mask is True)\n",
    "        diff = diff * (~expanded_mask)  # Keep valid pixels only\n",
    "\n",
    "        # Sum over the channel and spatial dimensions (H, W)\n",
    "        loss = diff.sum(dim=(1, 2, 3))\n",
    "\n",
    "        # Count the number of valid pixels per batch (sum of ~mask)\n",
    "        num_valid_pixels = (~expanded_mask).sum(dim=(1, 2, 3)).float()\n",
    "\n",
    "        # Prevent division by zero (in case all pixels are NoData)\n",
    "        num_valid_pixels = torch.clamp(num_valid_pixels, min=1.0)\n",
    "\n",
    "        # Compute the mean loss per valid pixel\n",
    "        loss = loss / num_valid_pixels\n",
    "\n",
    "        # Return the mean loss over the batch\n",
    "        return loss.mean()\n",
    "\n",
    "def r2_score_torch(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the R² score in PyTorch to avoid moving tensors to CPU.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Ground truth tensor (valid pixels, num_channels).\n",
    "    - y_pred: Predicted tensor (valid pixels, num_channels).\n",
    "\n",
    "    Returns:\n",
    "    - r2: The R² score computed in PyTorch.\n",
    "    \"\"\"\n",
    "    # Mean of the true values\n",
    "    y_true_mean = torch.mean(y_true, dim=0)\n",
    "\n",
    "    # Total sum of squares (TSS)\n",
    "    total_variance = torch.sum((y_true - y_true_mean) ** 2, dim=0)\n",
    "\n",
    "    # Residual sum of squares (RSS)\n",
    "    residuals = torch.sum((y_true - y_pred) ** 2, dim=0)\n",
    "\n",
    "    # Compute R² score for each channel and take mean\n",
    "    r2 = 1 - (residuals / total_variance)\n",
    "    return r2.mean()  # Mean R² across all channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning Module\n",
    "class UNetLightning(pl.LightningModule):\n",
    "    def __init__(self, in_channels, out_channels=9, learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_channels (list): Number of input channels for each dataset.\n",
    "            out_channels (int): Number of output channels.\n",
    "            optimizer_type (str): Type of optimizer ('adam', 'sgd', etc.).\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            scheduler_type (str): Type of scheduler ('plateau', etc.).\n",
    "            scheduler_params (dict): Parameters for the scheduler (e.g., 'patience', 'factor' for ReduceLROnPlateau).\n",
    "        \"\"\"\n",
    "        super(UNetLightning, self).__init__()\n",
    "        \n",
    "        # Define the U-Net architecture\n",
    "        self.enc_conv0 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
    "        self.enc_conv1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.enc_conv2 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.enc_conv3 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec_conv3 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.dec_conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.dec_conv1 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.dec_conv0 = nn.Conv2d(64, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Use the MaskedMSELoss\n",
    "        self.criterion = MaskedMSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.enc_conv0(x))\n",
    "        x2 = self.pool(x1)\n",
    "        x2 = F.relu(self.enc_conv1(x2))\n",
    "        x3 = self.pool(x2)\n",
    "        x3 = F.relu(self.enc_conv2(x3))\n",
    "        x4 = self.pool(x3)\n",
    "        x4 = F.relu(self.enc_conv3(x4))\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up(x4)\n",
    "        x = F.relu(self.dec_conv3(x))\n",
    "        x = self.up(x)\n",
    "        x = F.relu(self.dec_conv2(x))\n",
    "        x = self.up(x)\n",
    "        x = F.relu(self.dec_conv1(x))\n",
    "        x = self.dec_conv0(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets, masks = batch\n",
    "        outputs = self(inputs)  # Forward pass\n",
    "        # Expand the mask to match the number of channels in outputs and targets\n",
    "        expanded_mask = masks.unsqueeze(1).expand_as(outputs)  # Shape: (batch_size, num_channels, H, W)\n",
    "\n",
    "        # Exclude NoData pixels by applying the mask (keep only valid pixels)\n",
    "        valid_outputs = outputs.masked_select(~expanded_mask).view(-1, outputs.size(1))\n",
    "        valid_targets = targets.masked_select(~expanded_mask).view(-1, targets.size(1))\n",
    "\n",
    "        # Compute the masked loss\n",
    "        loss = self.criterion(outputs, targets, masks)\n",
    "        # Calculate R² score for valid pixels\n",
    "        r2 = r2_score_torch(valid_targets, valid_outputs)  # R² calculated in PyTorch\n",
    "\n",
    "        # Log the training loss and R² score\n",
    "        self.log('train_loss', loss, logger=True)\n",
    "        self.log('train_r2', r2, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets, masks = batch\n",
    "        outputs = self(inputs)  # Forward pass\n",
    "        # Expand the mask to match the number of channels in outputs and targets\n",
    "        expanded_mask = masks.unsqueeze(1).expand_as(outputs)  # Shape: (batch_size, num_channels, H, W)\n",
    "\n",
    "        # Exclude NoData pixels by applying the mask (keep only valid pixels)\n",
    "        valid_outputs = outputs.masked_select(~expanded_mask).view(-1, outputs.size(1))\n",
    "        valid_targets = targets.masked_select(~expanded_mask).view(-1, targets.size(1))\n",
    "        \n",
    "        # Compute the masked loss\n",
    "        loss = self.criterion(outputs, targets, masks)\n",
    "        # Calculate R² score for valid pixels\n",
    "        r2 = r2_score_torch(valid_targets, valid_outputs)  # R² calculated in PyTorch\n",
    "\n",
    "        # Log the validation loss and R² score\n",
    "        self.log('val_loss', loss, logger=True)\n",
    "        self.log('val_r2', r2, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets, masks = batch\n",
    "        outputs = self(inputs)  # Forward pass\n",
    "\n",
    "        expanded_mask = masks.unsqueeze(1).expand_as(outputs)\n",
    "        valid_outputs = outputs.masked_select(~expanded_mask).view(-1, outputs.size(1))\n",
    "        valid_targets = targets.masked_select(~expanded_mask).view(-1, targets.size(1))\n",
    "        \n",
    "        # Compute the masked loss\n",
    "        loss = self.criterion(outputs, targets, masks)\n",
    "        \n",
    "        # Calculate R² score for valid pixels\n",
    "        r2 = r2_score_torch(valid_targets, valid_outputs)  # R² calculated in PyTorch\n",
    "\n",
    "        # Log the test loss and R² score\n",
    "        self.log('test_loss', loss, logger=True)\n",
    "        self.log('test_r2', r2, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSpeciesDataset(Dataset):\n",
    "    def __init__(self, tile_names, processed_dir, datasets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_names (list): List of tile filenames to load.\n",
    "            processed_dir (str): Base directory containing the processed data folders.\n",
    "            datasets (list): List of dataset folder names to include (e.g., ['s2/spring', 's2/summer', 'topo', 'climate']).\n",
    "        \"\"\"\n",
    "        self.tile_names = tile_names\n",
    "        self.processed_dir = processed_dir\n",
    "        self.datasets = datasets  # List of dataset folder names\n",
    "\n",
    "        # Calculate total input channels automatically\n",
    "        self.total_input_channels = self.calculate_total_input_channels()\n",
    "\n",
    "    def calculate_total_input_channels(self):\n",
    "        \"\"\"\n",
    "        Calculate the total number of input channels by inspecting one file from each dataset.\n",
    "        \"\"\"\n",
    "        total_channels = 0\n",
    "        for dataset in self.datasets:\n",
    "            example_file = os.path.join(self.processed_dir, dataset, self.tile_names[0])  # Use first tile to inspect\n",
    "            with rasterio.open(example_file) as src:\n",
    "                total_channels += src.count  # Add the number of bands in the dataset\n",
    "        return total_channels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tile_name = self.tile_names[idx]\n",
    "        input_data_list = []\n",
    "\n",
    "        # Load data from each dataset (spring, summer, topo, climate, etc.)\n",
    "        for dataset in self.datasets:\n",
    "            dataset_path = os.path.join(self.processed_dir, dataset, tile_name)\n",
    "            with rasterio.open(dataset_path) as src:\n",
    "                input_data = src.read()  # Read the bands (num_bands, H, W)\n",
    "                input_data_list.append(input_data)\n",
    "\n",
    "        # Combine all the input data into a single input tensor\n",
    "        input_data = np.concatenate(input_data_list, axis=0)  # Concatenate along the channel axis\n",
    "\n",
    "        # Load the corresponding label (target species composition)\n",
    "        label_path = os.path.join(self.processed_dir, 'labels/tiles_128', tile_name)\n",
    "        with rasterio.open(label_path) as src:\n",
    "            target_data = src.read()  # (num_bands, H, W)\n",
    "            nodata_value_label = src.nodata  # NoData value for the labels\n",
    "\n",
    "            # Create a NoData mask for the target data\n",
    "            if nodata_value_label is not None:\n",
    "                mask = np.any(target_data == nodata_value_label, axis=0)  # Collapse bands to (H, W)\n",
    "            else:\n",
    "                mask = np.zeros_like(target_data[0], dtype=bool)  # Assume all valid if no NoData value\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        input_tensor = torch.from_numpy(input_data).float()  # Shape: (total_input_channels, H, W)\n",
    "        target_tensor = torch.from_numpy(target_data).float()  # Shape: (num_output_channels, H, W)\n",
    "        mask_tensor = torch.from_numpy(mask).bool()  # Shape: (H, W), NoData mask\n",
    "\n",
    "        return input_tensor, target_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSpeciesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, tile_names, processed_dir, datasets_to_use, batch_size=4, num_workers=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_names (list): List of tile filenames to load.\n",
    "            processed_dir (str): Directory where processed data is located.\n",
    "            datasets_to_use (list): List of dataset names to include (e.g., ['s2/spring', 's2/summer', 'topo']).\n",
    "            batch_size (int): Batch size for DataLoader.\n",
    "            num_workers (int): Number of workers for DataLoader.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tile_names = tile_names\n",
    "        self.processed_dir = processed_dir\n",
    "        self.datasets_to_use = datasets_to_use\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        # Calculate total input channels based on the datasets\n",
    "        temp_dataset = TreeSpeciesDataset(self.tile_names['train'], self.processed_dir, self.datasets_to_use)\n",
    "        self.input_channels = temp_dataset.total_input_channels\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Sets up the dataset for train, validation, and test splits.\n",
    "        \"\"\"\n",
    "        # Create datasets for train, validation, and test\n",
    "        self.train_dataset = TreeSpeciesDataset(self.tile_names['train'], self.processed_dir, self.datasets_to_use)\n",
    "        self.val_dataset = TreeSpeciesDataset(self.tile_names['val'], self.processed_dir, self.datasets_to_use)\n",
    "        self.test_dataset = TreeSpeciesDataset(self.tile_names['test'], self.processed_dir, self.datasets_to_use)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tile_names(file_path):\n",
    "    \"\"\"\n",
    "    Load tile names from a .txt file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .txt file.\n",
    "\n",
    "    Returns:\n",
    "        tile_names (list): List of tile names.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        tile_names = f.read().splitlines()\n",
    "    return tile_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datasets_to_use, resolution, log_name, num_epoch=10):\n",
    "    wandb.init()\n",
    "    # Tile names for train, validation, and test\n",
    "    tile_names = {\n",
    "        'train': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/train_tiles.txt'),\n",
    "        'val': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/val_tiles.txt'),\n",
    "        'test': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/test_tiles.txt')\n",
    "    }\n",
    "    # Initialize the DataModule\n",
    "    data_module = TreeSpeciesDataModule(\n",
    "        tile_names=tile_names,\n",
    "        processed_dir=f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m',  # Base directory where the datasets are stored\n",
    "        datasets_to_use=datasets_to_use,\n",
    "        batch_size=4,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Use the calculated input channels from the DataModule to initialize the model\n",
    "    model = UNetLightning(in_channels=data_module.input_channels, learning_rate=1e-3)\n",
    "\n",
    "    # Define a checkpoint callback to save the best model\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',  # Track the validation loss\n",
    "        filename='best-model-{epoch:02d}-{val_loss:.2f}',\n",
    "        save_top_k=1,  # Only save the best model\n",
    "        mode='min'  # We want to minimize the validation loss\n",
    "    )\n",
    "\n",
    "    csv_logger = CSVLogger(save_dir='logs/csv_logs', name=log_name)\n",
    "    wandb_logger = WandbLogger(name=log_name, save_dir='logs/wandb_logs', offline=True)\n",
    "    \n",
    "    # Create a PyTorch Lightning Trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=num_epoch,\n",
    "        logger=[wandb_logger, csv_logger],\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    wandb_logger.log_text('parameters.txt', dataframe=pd.DataFrame({'datasets': [datasets_to_use], 'num_epoches': num_epoch, 'resolution': resolution}))\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # Test the model after training\n",
    "    trainer.test(model, data_module)\n",
    "\n",
    "    # Save the best model after training\n",
    "    trainer.save_checkpoint(f\"logs/checkpoints/{log_name}/final_model.pt\")\n",
    "    # Load the saved model\n",
    "    #model = UNetLightning.load_from_checkpoint(\"final_model.ckpt\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 5.2 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.433    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:18<00:00, 10.33it/s, v_num=h_73, train_r2=0.645, val_r2=0.391]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:18<00:00, 10.13it/s, v_num=h_73, train_r2=0.645, val_r2=0.391]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:02<00:00, 14.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03279959037899971    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37593594193458557    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03279959037899971   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37593594193458557   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/fall/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory wandb/lightning_logs/xul99rdh/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 7.0 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.440    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:33<00:00,  7.62it/s, v_num=h_60, train_r2=0.470, val_r2=0.429]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:33<00:00,  7.59it/s, v_num=h_60, train_r2=0.470, val_r2=0.429]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 153/153 [01:24<00:00,  1.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03038182482123375    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45745348930358887    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03038182482123375   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45745348930358887   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/fall/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 5.2 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.433    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:19<00:00,  9.36it/s, v_num=h_64, train_r2=0.277, val_r2=0.439]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:19<00:00,  9.36it/s, v_num=h_64, train_r2=0.277, val_r2=0.439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0294065959751606     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44705334305763245    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0294065959751606    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44705334305763245   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_to_use=['rmf_s2/summer/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory wandb/lightning_logs/xul99rdh/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 7.0 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.440    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:17<00:00,  9.23it/s, v_num=h_63, train_r2=0.541, val_r2=0.451]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:17<00:00,  9.23it/s, v_num=h_63, train_r2=0.541, val_r2=0.451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 153/153 [01:02<00:00,  2.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.02936221845448017    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4824545979499817     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.02936221845448017   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4824545979499817    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_to_use=['rmf_s2/summer/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 5.2 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.433    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:18<00:00,  9.84it/s, v_num=h_65, train_r2=-0.21, val_r2=0.376]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:18<00:00,  9.83it/s, v_num=h_65, train_r2=-0.21, val_r2=0.376]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:14<00:00,  2.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.032771870493888855    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37339767813682556    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.032771870493888855   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37339767813682556   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_to_use=['rmf_s2/spring/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 7.0 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.440    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 17/713 [00:12<08:20,  1.39it/s, v_num=h_66, train_r2=0.311] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:15<00:00,  9.41it/s, v_num=h_66, train_r2=0.356, val_r2=0.452]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:15<00:00,  9.41it/s, v_num=h_66, train_r2=0.356, val_r2=0.452]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 153/153 [01:10<00:00,  2.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.029583735391497612    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4722636640071869     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.029583735391497612   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4722636640071869    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_to_use=['rmf_s2/spring/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### winter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 5.2 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.433    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  37%|███▋      | 68/186 [00:31<00:55,  2.14it/s, v_num=h_67, train_r2=0.133]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:19<00:00,  9.75it/s, v_num=h_67, train_r2=0.389, val_r2=0.375]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:19<00:00,  9.55it/s, v_num=h_67, train_r2=0.389, val_r2=0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:13<00:00,  3.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03315405547618866    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3680827021598816     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03315405547618866   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3680827021598816    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_to_use=['rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 7.0 K  | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.440    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|█▊        | 129/713 [00:53<04:00,  2.43it/s, v_num=h_68, train_r2=0.311]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:17<00:00,  9.16it/s, v_num=h_68, train_r2=0.0604, val_r2=0.364]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:17<00:00,  9.16it/s, v_num=h_68, train_r2=0.0604, val_r2=0.364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 153/153 [00:55<00:00,  2.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03436056151986122    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37599560618400574    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03436056151986122   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37599560618400574   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_to_use=['rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combined dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m: dem, e: slope; a: aspect; t: trasp; twi: i; c: climate; p: phenology; s4: 4 season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 20.8 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 145/186 [00:25<00:07,  5.76it/s, v_num=h_69, train_r2=0.370]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:38<00:00,  4.88it/s, v_num=h_69, train_r2=0.415, val_r2=0.473]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:38<00:00,  4.87it/s, v_num=h_69, train_r2=0.415, val_r2=0.473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:06<00:00,  6.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.028345398604869843    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.47548022866249084    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.028345398604869843   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.47548022866249084   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 27.7 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.523    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  32%|███▏      | 228/713 [00:50<01:47,  4.50it/s, v_num=h_70, train_r2=0.615]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [02:55<00:00,  4.06it/s, v_num=h_70, train_r2=0.708, val_r2=0.469]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [02:55<00:00,  4.06it/s, v_num=h_70, train_r2=0.708, val_r2=0.469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 153/153 [00:37<00:00,  4.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.028624823316931725    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5034624934196472     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.028624823316931725   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5034624934196472    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summer+fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 10.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.454    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:24<00:00,  7.53it/s, v_num=h_71, train_r2=0.514, val_r2=0.454]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:24<00:00,  7.52it/s, v_num=h_71, train_r2=0.514, val_r2=0.454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:04<00:00,  9.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.029015520587563515    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45965221524238586    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.029015520587563515   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45965221524238586   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = datasets_to_use = ['rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "###### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 13.9 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.468    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:48<00:00,  6.54it/s, v_num=h_72, train_r2=0.722, val_r2=0.447]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 713/713 [01:48<00:00,  6.54it/s, v_num=h_72, train_r2=0.722, val_r2=0.447]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 153/153 [00:18<00:00,  8.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.02947103977203369    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4837731420993805     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.02947103977203369   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4837731420993805    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = datasets_to_use = ['rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "##### 4-season + climate_imagederived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 41.5 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.579    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 186/186 [01:04<00:00,  2.87it/s, v_num=h_81, train_r2=0.488, val_r2=0.375]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 186/186 [01:04<00:00,  2.87it/s, v_num=h_81, train_r2=0.488, val_r2=0.375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:10<00:00,  3.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03311808034777641    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.367619127035141     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03311808034777641   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.367619127035141    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_imagery_climate/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + spl_climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 41.5 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.579    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:10<00:00,  2.64it/s, v_num=mi_1, train_r2=0.073, val_r2=0.371]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:10<00:00,  2.64it/s, v_num=mi_1, train_r2=0.073, val_r2=0.371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03331870958209038    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36944127082824707    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03331870958209038   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36944127082824707   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▄▅▄▅▄▃▅▅▄▇▄▄▃▇▃▄▃▄▂▅▃▃▁▄▁▃▃▄▃▃▅▃▂▂▄</td></tr><tr><td>train_r2</td><td>▁▄▆▅▅▄▁▅▅▅▅▃▆▆▇▂▆▄▆▇▆▆▅▅▆▄▇▆█▅▅▄▇▆▅▇▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▁▁▁▁▁</td></tr><tr><td>val_r2</td><td>▁▅▆▆▇███▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03332</td></tr><tr><td>test_r2</td><td>0.36944</td></tr><tr><td>train_loss</td><td>0.03183</td></tr><tr><td>train_r2</td><td>0.37855</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03451</td></tr><tr><td>val_r2</td><td>0.37079</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_112928-in7j7lmi<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_112928-in7j7lmi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_climate/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, '4s_spl_climate', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + phenology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:58<00:00,  3.16it/s, v_num=h_76, train_r2=0.664, val_r2=0.434]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:59<00:00,  3.11it/s, v_num=h_76, train_r2=0.664, val_r2=0.434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:11<00:00,  3.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.030135922133922577    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4315565526485443     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.030135922133922577   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4315565526485443    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_phenology/tiles_128']\n",
    "\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + ASTE TOPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:59<00:00,  3.11it/s, v_num=h_77, train_r2=0.284, val_r2=0.371]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:59<00:00,  3.11it/s, v_num=h_77, train_r2=0.284, val_r2=0.371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:11<00:00,  3.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03330802172422409    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36397215723991394    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03330802172422409   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36397215723991394   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_topo/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season+spl_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory wandb/lightning_logs/xul99rdh/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:00<00:00,  3.09it/s, v_num=h_78, train_r2=0.0207, val_r2=0.370]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:00<00:00,  3.09it/s, v_num=h_78, train_r2=0.0207, val_r2=0.370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:11<00:00,  3.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03316814824938774    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3674585819244385     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03316814824938774   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3674585819244385    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_dem/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:50<00:00,  3.66it/s, v_num=5l_0, train_r2=0.659, val_r2=0.348]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:50<00:00,  3.66it/s, v_num=5l_0, train_r2=0.659, val_r2=0.348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03543954715132713    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32690727710723877    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03543954715132713   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32690727710723877   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▄█▃▄▂▂▃▂▃▄▄▂▂▂▃▃▁▃▄▄▂▅▂▅▃▇▇█▁▃▂▅▄▁▂▂</td></tr><tr><td>train_r2</td><td>▅▇▄▆▄▆█▆▅▄▅▅▇▇▇▇▄▅▅▄▄▇▄▆▅▆▄▁▄▇█▇▅▆▇█▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▃▂▂▁▄</td></tr><tr><td>val_r2</td><td>▁▆▆▆▇▆▇▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03544</td></tr><tr><td>test_r2</td><td>0.32691</td></tr><tr><td>train_loss</td><td>0.03129</td></tr><tr><td>train_r2</td><td>0.40351</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03563</td></tr><tr><td>val_r2</td><td>0.34792</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_084328-1rlx8e5l<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_084328-1rlx8e5l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_slope/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s4_aster_e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:55<00:00,  3.36it/s, v_num=dw_0, train_r2=0.343, val_r2=0.377]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:55<00:00,  3.36it/s, v_num=dw_0, train_r2=0.343, val_r2=0.377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0329463928937912     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37245768308639526    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0329463928937912    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37245768308639526   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▇▄▄▁▂▄▂▃▃▃▅▇▃▄▅▂▂▄▂▅▂▁▄▃▅▂▃▂▂▄▄█▂▂▁▃</td></tr><tr><td>train_r2</td><td>▅▃▅▄▆▆▆▅▆▆▆▃▃▇▆▂▅▄█▆▄▇▇▅▄▅█▆▆▆▅▇▁▆▇▆▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>▇▇█▄▄▂▃▂▁▁</td></tr><tr><td>val_r2</td><td>▂▂▁▅▆▇▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03295</td></tr><tr><td>test_r2</td><td>0.37246</td></tr><tr><td>train_loss</td><td>0.03233</td></tr><tr><td>train_r2</td><td>0.48545</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03428</td></tr><tr><td>val_r2</td><td>0.37736</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_085240-a0l9f8dw<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_085240-a0l9f8dw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_slope/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s4_spl_e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:53<00:00,  3.48it/s, v_num=3i_0, train_r2=0.397, val_r2=0.371]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:53<00:00,  3.48it/s, v_num=3i_0, train_r2=0.397, val_r2=0.371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03326144441962242    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.364913672208786     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03326144441962242   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.364913672208786    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▅▄▂▄█▃▇▄▃▄▄▄▄▃▂▂▃▂▇▂▆▄▃▃▄▅▄▅▃▂▁▄▂▃▃▃▂</td></tr><tr><td>train_r2</td><td>▅▃▅▆▂▄▂▄▆▂▇▇▄█▄▆▂▅▁█▃▃▃▃▄▃▅▅▂▆█▆█▇▅▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▅▆▅▃▃▁▁▃</td></tr><tr><td>val_r2</td><td>▁▅▄▃▄▆▇██▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03326</td></tr><tr><td>test_r2</td><td>0.36491</td></tr><tr><td>train_loss</td><td>0.02936</td></tr><tr><td>train_r2</td><td>0.42168</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03457</td></tr><tr><td>val_r2</td><td>0.37104</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_094240-6z7kn83i<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_094240-6z7kn83i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_aspect/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s2_aster_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:54<00:00,  3.42it/s, v_num=3a_0, train_r2=0.537, val_r2=0.383]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:54<00:00,  3.39it/s, v_num=3a_0, train_r2=0.537, val_r2=0.383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:09<00:00,  4.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03299973905086517    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37292107939720154    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03299973905086517   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37292107939720154   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▆▅▄▁▄▂▄▇▄█▂▇▄▄▄▅▆▃▅▅▂▅▅▃▃▃▃▅▃▅▄▅▂▃▅▂▆</td></tr><tr><td>train_r2</td><td>▂▃▄█▄▇▅▁▅▁▇▅▆▆▅▆▇▆▃▃▅▅▅▄▇▅█▅▆▆▆▆█▅▆▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▄▄▂▂▃▂▂▁</td></tr><tr><td>val_r2</td><td>▁▃▅▆▆█▆███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.033</td></tr><tr><td>test_r2</td><td>0.37292</td></tr><tr><td>train_loss</td><td>0.04404</td></tr><tr><td>train_r2</td><td>0.2223</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03366</td></tr><tr><td>val_r2</td><td>0.38287</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_093323-blnv8m3a<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_093323-blnv8m3a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_aspect/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s2_spl_a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + trasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:52<00:00,  3.53it/s, v_num=up_0, train_r2=nan.0, val_r2=nan.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:52<00:00,  3.53it/s, v_num=up_0, train_r2=nan.0, val_r2=nan.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>nan</td></tr><tr><td>test_r2</td><td>nan</td></tr><tr><td>train_loss</td><td>nan</td></tr><tr><td>train_r2</td><td>nan</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>nan</td></tr><tr><td>val_r2</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_100122-3ro2rwup<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_100122-3ro2rwup/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_trasp/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s2_aster_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:54<00:00,  3.43it/s, v_num=0m_0, train_r2=0.291, val_r2=0.372]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:54<00:00,  3.43it/s, v_num=0m_0, train_r2=0.291, val_r2=0.372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:09<00:00,  4.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.033179812133312225    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3655858337879181     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.033179812133312225   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3655858337879181    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▅▇▃▄▄▅▄▄▂▅▃▁▄▄▂▂▄▃▆▆▄▃▇▃▃▂█▄▂▅▄▂▆▂▅▇▅</td></tr><tr><td>train_r2</td><td>▄▂▅▄▅▅▄▄█▅▆▇▅▂▇▇▄▆▆▄▇▇▁▆▆▆▃▆▇▅▃▆▂█▃▅▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▇▃▂▁▁▂▁▁▁</td></tr><tr><td>val_r2</td><td>▁▂▆▇████▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03318</td></tr><tr><td>test_r2</td><td>0.36559</td></tr><tr><td>train_loss</td><td>0.04196</td></tr><tr><td>train_r2</td><td>0.2706</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03441</td></tr><tr><td>val_r2</td><td>0.37249</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_095205-tcle4q0m<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_095205-tcle4q0m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_trasp/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s2_spl_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + twi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:53<00:00,  3.49it/s, v_num=7p_0, train_r2=0.403, val_r2=0.393]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:53<00:00,  3.46it/s, v_num=7p_0, train_r2=0.403, val_r2=0.393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:09<00:00,  4.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03208437189459801    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.38807985186576843    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03208437189459801   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.38807985186576843   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▄▄▆▆▃▄▅▂▁▄▄▅▂▄▄▄▅▄▄▅▁▄▃▃▆▇▂▄▅▂▃▄▆█▃▅▆</td></tr><tr><td>train_r2</td><td>▅▄▅▁█▅▅▆▆█▇▅▆▇▆▅▆▅█▃█▇█▇▄▁▇▆▆█▆▆▄▂▆▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄█▅▃▂▂▃▂▁</td></tr><tr><td>val_r2</td><td>▂▅▁▄▇▇▇▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03208</td></tr><tr><td>test_r2</td><td>0.38808</td></tr><tr><td>train_loss</td><td>0.04625</td></tr><tr><td>train_r2</td><td>0.14776</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03344</td></tr><tr><td>val_r2</td><td>0.39254</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_090138-9y4o3c7p<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_090138-9y4o3c7p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name=\"s4_aster_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + spl_twi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 21.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.498    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:48<00:00,  3.85it/s, v_num=kb_0, train_r2=0.367, val_r2=0.369]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:48<00:00,  3.85it/s, v_num=kb_0, train_r2=0.367, val_r2=0.369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03325790539383888    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36377882957458496    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03325790539383888   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36377882957458496   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▃▄▄▄▄▅▅▃▂▅▅▅▄█▄▅▁▅▃▂▃▃▂▆▄▄▂▄▄▄▃▅▄▅▅▄</td></tr><tr><td>train_r2</td><td>▅▆▅▆▅▅▄▇▅▅▃▄▇▅▁▆▃▇▆▆▇▆▆▇▄▄▅█▆▇█▆▅▅▅▇▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▁▂▁▁▁</td></tr><tr><td>val_r2</td><td>▁▄▆▆██▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03326</td></tr><tr><td>test_r2</td><td>0.36378</td></tr><tr><td>train_loss</td><td>0.0358</td></tr><tr><td>train_r2</td><td>0.06589</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03448</td></tr><tr><td>val_r2</td><td>0.36892</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_114154-lursdrkb<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_114154-lursdrkb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='s4_spl_i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10, num_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + spl: slope + aspect + topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 22.5 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.503    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  47%|████▋     | 88/186 [00:38<00:42,  2.31it/s, v_num=r1_3, train_r2=0.314]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:10<00:00,  2.65it/s, v_num=r1_3, train_r2=0.0526, val_r2=0.374]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:10<00:00,  2.65it/s, v_num=r1_3, train_r2=0.0526, val_r2=0.374]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:14<00:00,  2.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03356863558292389    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3642759621143341     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03356863558292389   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3642759621143341    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▃█▆▄▃▅▅▆▄▃▃▄▄▆▄▄▁▃▄▂▄▅▇▃▃▆▄▄▆▃▆▇▂▃▃▄</td></tr><tr><td>train_r2</td><td>▂▅▆▃▅▅▅▆▃▆▅▅▄▄▃▇▆█▇▆▇▆▃▁▆▇▅▄▆▆▇▃▄▇▄▇▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▁▁▄▁</td></tr><tr><td>val_r2</td><td>▁▅▆▆▇▇██▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03357</td></tr><tr><td>test_r2</td><td>0.36428</td></tr><tr><td>train_loss</td><td>0.03107</td></tr><tr><td>train_r2</td><td>0.40179</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03445</td></tr><tr><td>val_r2</td><td>0.37379</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240929_092308-65lc31r1<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240929_092308-65lc31r1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_dem/tiles_128', 'rmf_spl_slope/tiles_128', 'rmf_spl_aspect/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_spl_mea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 22.0 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.500    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:43<00:00,  4.23it/s, v_num=37, train_r2=0.457, val_r2=0.371]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:44<00:00,  4.20it/s, v_num=37, train_r2=0.457, val_r2=0.371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:07<00:00,  5.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03380639851093292    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3623181879520416     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03380639851093292   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3623181879520416    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_dem/tiles_128', 'rmf_spl_slope/tiles_128', 'rmf_spl_trasp/tiles_128', 'rmf_spl_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_spl_meti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + aster: slope + trasp + twi + topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 23.1 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.505    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|██████▋   | 124/186 [00:43<00:21,  2.88it/s, v_num=h0_0, train_r2=nan.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:17<00:00,  2.41it/s, v_num=h0_0, train_r2=nan.0, val_r2=nan.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:17<00:00,  2.41it/s, v_num=h0_0, train_r2=nan.0, val_r2=nan.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:13<00:00,  2.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>nan</td></tr><tr><td>test_r2</td><td>nan</td></tr><tr><td>train_loss</td><td>nan</td></tr><tr><td>train_r2</td><td>nan</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>nan</td></tr><tr><td>val_r2</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240929_091004-bqodq9h0<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240929_091004-bqodq9h0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_topo/tiles_128', 'rmf_aster_slope/tiles_128', 'rmf_aster_trasp/tiles_128', 'rmf_aster_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_aster_meti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + aster: slope + aspect + topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 22.5 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.503    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:57<00:00,  3.25it/s, v_num=d8_0, train_r2=0.104, val_r2=0.377]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [00:57<00:00,  3.23it/s, v_num=d8_0, train_r2=0.104, val_r2=0.377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.032906122505664825    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37058568000793457    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.032906122505664825   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37058568000793457   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▄▄▅▃▅▆▂▅▅▃▂▃▅█▅▂▄▂█▃▄▃▂▁▅▅▇▄▄▄▆▇▃▃▄▄▃</td></tr><tr><td>train_r2</td><td>▅▆▃▆▅▄█▅▅▆▆▇▆▁▄▇▁▇▂▇█▅█▇▅▇▃▆█▅▄▄▇▇▇▇▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▄▂▃▄▂▄▁▁</td></tr><tr><td>val_r2</td><td>▁▅▅▆▆▅█▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03291</td></tr><tr><td>test_r2</td><td>0.37059</td></tr><tr><td>train_loss</td><td>0.02983</td></tr><tr><td>train_r2</td><td>0.52211</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03403</td></tr><tr><td>val_r2</td><td>0.37721</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_115024-p7krqtd8<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_115024-p7krqtd8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_topo/tiles_128', 'rmf_aster_slope/tiles_128', 'rmf_aster_aspect/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_aster_mea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-season + climate + phenology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 42.1 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.581    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:03<00:00,  2.94it/s, v_num=2j_0, train_r2=0.154, val_r2=0.423]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:03<00:00,  2.92it/s, v_num=2j_0, train_r2=0.154, val_r2=0.423]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:12<00:00,  3.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.030891502276062965    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4153890013694763     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.030891502276062965   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4153890013694763    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▃▃▃▄▅▅▃▃█▃▅▄▅▃▅▅▄▇▂▇▃▂▃▃▆▅▅▄▃▁▄▄▃▄▄▄</td></tr><tr><td>train_r2</td><td>▅▅▅█▅▅▅▆▇▃▆▄▇▆▇▅▆▇▆█▆█▇▇▆▁▆▅▇▅█▇▆▇▆▇▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▂▃▂▃▁</td></tr><tr><td>val_r2</td><td>▁▃▄▄▅▇▆▇▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03089</td></tr><tr><td>test_r2</td><td>0.41539</td></tr><tr><td>train_loss</td><td>0.03635</td></tr><tr><td>train_r2</td><td>0.37906</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03173</td></tr><tr><td>val_r2</td><td>0.42327</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_123547-d1r01k2j<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_123547-d1r01k2j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_imagery_climate/tiles_128', 'rmf_phenology/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_cp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 42.1 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.581    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:27<00:00,  2.12it/s, v_num=gz_0, train_r2=0.588, val_r2=0.377]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:28<00:00,  2.11it/s, v_num=gz_0, train_r2=0.588, val_r2=0.377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:14<00:00,  2.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.033067651093006134    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3695935904979706     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.033067651093006134   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3695935904979706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▂▄▂▅▂▆▃▃▃▄▁▃▄▃▃▃▄▅▄▆▄▃▄▃▁▆▃▃▃▃▅▁▃▄▆█▂</td></tr><tr><td>train_r2</td><td>▆▄▄▅▇▇▆▆▆▅█▃▄▆▅▆▄▄▅▃▂▆▄▂▆▄▅▄▅▆▃▆▃▄▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>▆▅▃▄█▃▂▂▂▁</td></tr><tr><td>val_r2</td><td>▄▄▆▄▁▅▆▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03307</td></tr><tr><td>test_r2</td><td>0.36959</td></tr><tr><td>train_loss</td><td>0.03101</td></tr><tr><td>train_r2</td><td>0.22938</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.0343</td></tr><tr><td>val_r2</td><td>0.37727</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_134346-r601m2gz<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_134346-r601m2gz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_climate/tiles_128', 'rmf_phenology/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_scp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-season + climate + phenology + dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 42.7 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.583    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:02<00:00,  2.99it/s, v_num=p9_0, train_r2=0.169, val_r2=0.394]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:02<00:00,  2.99it/s, v_num=p9_0, train_r2=0.169, val_r2=0.394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:10<00:00,  3.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03216205909848213    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3907514214515686     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03216205909848213   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3907514214515686    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▆▃▇▅▄█▅▅▄▃▃▂▂█▂▃▄▄▅▃▁▃▂▅▄▇▂▁▄█▄▅▄▂▇▂</td></tr><tr><td>train_r2</td><td>▅▆▇▅▅▆▁▃▅▇▆▆▆▇▄▆▇▃▅▅▇█▆▆▅▆▅▆█▅▃▅▆▆█▅▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▆▃▇▁▅▃▁▃</td></tr><tr><td>val_r2</td><td>▁▄▂▆▁█▄▆█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03216</td></tr><tr><td>test_r2</td><td>0.39075</td></tr><tr><td>train_loss</td><td>0.02029</td></tr><tr><td>train_r2</td><td>0.61648</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03306</td></tr><tr><td>val_r2</td><td>0.39361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_130535-4vyhn3p9<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_130535-4vyhn3p9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_imagery_climate/tiles_128', 'rmf_phenology/tiles_128', 'rmf_aster_topo/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_aster_cpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 42.7 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.583    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:26<00:00,  2.15it/s, v_num=8z_0, train_r2=0.232, val_r2=0.371]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:26<00:00,  2.15it/s, v_num=8z_0, train_r2=0.232, val_r2=0.371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:13<00:00,  2.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03404741361737251    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35529762506484985    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03404741361737251   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35529762506484985   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▃▆▄▃▂▆▁▄▃▃▃█▅▅▅▄▄▅▂▇▆▂▄▃▂▁▃▂▂▄▄▄▄▁▂▄</td></tr><tr><td>train_r2</td><td>▆▅▇▆▃▆▁▆▄▆▆▆▂▅▄▁▆▄▄▇▂▄▇▆▅▆▅▆▇█▄▄█▁█▇▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▇▄▄▂▂▃▁▁</td></tr><tr><td>val_r2</td><td>▁▅▂▅▅▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03405</td></tr><tr><td>test_r2</td><td>0.3553</td></tr><tr><td>train_loss</td><td>0.03793</td></tr><tr><td>train_r2</td><td>0.48602</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03436</td></tr><tr><td>val_r2</td><td>0.37143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_124638-9zs1m08z<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_124638-9zs1m08z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_climate/tiles_128', 'rmf_phenology/tiles_128', 'rmf_spl_dem/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_spl_cpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all - dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 23.1 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.505    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:15<00:00,  2.46it/s, v_num=xs_1, train_r2=0.0932, val_r2=0.383]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:16<00:00,  2.43it/s, v_num=xs_1, train_r2=0.0932, val_r2=0.383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:41<00:00,  0.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.032804835587739944    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37578335404396057    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.032804835587739944   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37578335404396057   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▃▄█▃▅▃▄▄▃▅▇█▄▃▂▃▆▂▅▂▂▅▂▄▅▄▅▃▄▂▂▁▃▄▅▅▃</td></tr><tr><td>train_r2</td><td>▅▃▂▆▅▄▅▄▇▄▁▄▅▇█▄▁▆▄█▆▅█▇▅▄▄▇▇▇▃█▇█▃▃▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▄▂▂▂▁</td></tr><tr><td>val_r2</td><td>▁▄▅▅▆▅▇▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.0328</td></tr><tr><td>test_r2</td><td>0.37578</td></tr><tr><td>train_loss</td><td>0.02877</td></tr><tr><td>train_r2</td><td>0.53964</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03381</td></tr><tr><td>val_r2</td><td>0.38343</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240929_085221-dccahqxs<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240929_085221-dccahqxs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_aster_topo/tiles_128', 'rmf_aster_slope/tiles_128', 'rmf_aster_aspect/tiles_128', 'rmf_aster_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_aster_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 23.7 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.507    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:19<00:00,  2.33it/s, v_num=mq_0, train_r2=0.434, val_r2=0.378]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:19<00:00,  2.33it/s, v_num=mq_0, train_r2=0.434, val_r2=0.378]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:13<00:00,  2.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03290411829948425    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3722131848335266     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03290411829948425   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3722131848335266    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▄▃▄▄▄▆▁▄▅▄▃▅▄▂▄▁▄▄▄▇▅▄▁▄▆▂▂▃█▃▃▄▅▂▃▄</td></tr><tr><td>train_r2</td><td>▁▄▅▅▃▄▂▅▄▂▅▆▅▄▆▆▇▄▅▆▂▆▄█▇▃▅▇▇▂▇▄▅▄▇▆▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▇▃▃▃▃▁▁▁▁</td></tr><tr><td>val_r2</td><td>▁▃▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.0329</td></tr><tr><td>test_r2</td><td>0.37221</td></tr><tr><td>train_loss</td><td>0.03697</td></tr><tr><td>train_r2</td><td>0.46453</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.034</td></tr><tr><td>val_r2</td><td>0.37799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_132958-d8f4ipmq<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_132958-d8f4ipmq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_trasp/tiles_128', 'rmf_spl_twi/tiles_128', 'rmf_spl_slope/tiles_128', 'rmf_spl_aspect/tiles_128', \\\n",
    "    'rmf_spl_dem/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_spl_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 44.4 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.590    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:28<00:00,  2.11it/s, v_num=t5_1, train_r2=0.474, val_r2=0.414]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 186/186 [01:29<00:00,  2.07it/s, v_num=t5_1, train_r2=0.474, val_r2=0.414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:13<00:00,  2.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.031480852514505386    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40487024188041687    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.031480852514505386   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40487024188041687   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▄▆▅▆▅▅▆▄▃▇█▅▄▄▄▄▄▁▄▇▆▁▃▅▃▇▄▆▂▄▄▃▃▄▃▃▇</td></tr><tr><td>train_r2</td><td>▄▄▁▅▅▅▅▃▅▆▅▄▁▆▇▆▄█▅▂▃▆▇▆▆▁▃▅▆██▅▆▆▆▇▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>▄█▃▃▃▂▃▂▁▁</td></tr><tr><td>val_r2</td><td>▅▁▅▆▆▇▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_loss</td><td>0.03148</td></tr><tr><td>test_r2</td><td>0.40487</td></tr><tr><td>train_loss</td><td>0.04722</td></tr><tr><td>train_r2</td><td>0.28864</td></tr><tr><td>trainer/global_step</td><td>1860</td></tr><tr><td>val_loss</td><td>0.03219</td></tr><tr><td>val_r2</td><td>0.41364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20240927_141036-ts2nuit5<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240927_141036-ts2nuit5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_imagery_climate/tiles_128', 'rmf_phenology/tiles_128', \\\n",
    "    'rmf_aster_topo/tiles_128', 'rmf_aster_slope/tiles_128', 'rmf_aster_aspect/tiles_128', 'rmf_aster_twi/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=10, log_name='4s_allaster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 45.0 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.592    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 186/186 [01:18<00:00,  2.38it/s, v_num=vf_1, train_r2=0.590, val_r2=0.384]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 186/186 [01:18<00:00,  2.37it/s, v_num=vf_1, train_r2=0.590, val_r2=0.384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:39<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03320503979921341    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3690541684627533     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03320503979921341   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3690541684627533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▁▃▃▂▄▂▃▄▅▅▂▅▆▂█▁▄▁▄▂▂▅▃▄▄▂▄▃▃▅▂▂▁▄▇▄▂▃▅▂</td></tr><tr><td>train_r2</td><td>█▅▅▇▇▇▇▄▅▅▂▅▂▁▅▆▇▇▇▅▃▂▆▇▇▅▂▆▆▅▄▆█▇▂▃▂▅█▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▅▃▆▄▄▃▃▄▂▂▃▂▂▂▁▂▁▁▁</td></tr><tr><td>val_r2</td><td>▁▄▆▅▅▅▆▆▆▇▇▆▇▇▇█▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>test_loss</td><td>0.03321</td></tr><tr><td>test_r2</td><td>0.36905</td></tr><tr><td>train_loss</td><td>0.02793</td></tr><tr><td>train_r2</td><td>0.39174</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_loss</td><td>0.0337</td></tr><tr><td>val_r2</td><td>0.38361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20241001_152140-cjultbvf<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241001_152140-cjultbvf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128', 'rmf_s2/winter/tiles_128', \\\n",
    "    'rmf_spl_climate/tiles_128', 'rmf_phenology/tiles_128', \\\n",
    "    'rmf_spl_trasp/tiles_128', 'rmf_spl_twi/tiles_128', 'rmf_spl_slope/tiles_128', 'rmf_spl_aspect/tiles_128', \\\n",
    "    'rmf_spl_dem/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, num_epoch=20, log_name='4s_allspl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagery + point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "import os\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, targets, mask):\n",
    "        \"\"\"\n",
    "        Custom MSE loss function that ignores NoData pixels.\n",
    "\n",
    "        Args:\n",
    "        - outputs: Predicted values (batch_size, num_channels, H, W)\n",
    "        - targets: Ground truth values (batch_size, num_channels, H, W)\n",
    "        - mask: Boolean mask indicating NoData pixels (batch_size, H, W)\n",
    "\n",
    "        Returns:\n",
    "        - loss: Mean squared error computed only for valid pixels.\n",
    "        \"\"\"\n",
    "        # Expand mask to match the shape of outputs and targets\n",
    "        expanded_mask = mask.unsqueeze(1).expand_as(outputs)  # Shape: (batch_size, num_channels, H, W)\n",
    "\n",
    "        # Compute squared differences, applying mask to ignore invalid pixels\n",
    "        diff = (outputs - targets) ** 2\n",
    "        valid_diff = diff * (~expanded_mask)  # Keep only valid pixels (where mask is False)\n",
    "\n",
    "        # Sum over the channel and spatial dimensions (H, W)\n",
    "        loss = valid_diff.sum(dim=(1, 2, 3))\n",
    "\n",
    "        # Count the number of valid pixels per batch (sum of ~mask)\n",
    "        num_valid_pixels = (~expanded_mask).sum(dim=(1, 2, 3)).float()\n",
    "\n",
    "        # Prevent division by zero (if all pixels are NoData)\n",
    "        num_valid_pixels = torch.clamp(num_valid_pixels, min=1.0)\n",
    "\n",
    "        # Compute mean squared error per valid pixel\n",
    "        loss = loss / num_valid_pixels\n",
    "\n",
    "        # Return the average loss over the batch\n",
    "        return loss.mean()\n",
    "\n",
    "def r2_score_torch(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the R² score in PyTorch to avoid moving tensors to CPU.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Ground truth tensor (valid pixels, num_channels).\n",
    "    - y_pred: Predicted tensor (valid pixels, num_channels).\n",
    "\n",
    "    Returns:\n",
    "    - r2: The R² score computed in PyTorch.\n",
    "    \"\"\"\n",
    "    # Mean of the true values\n",
    "    y_true_mean = torch.mean(y_true, dim=0)\n",
    "\n",
    "    # Total sum of squares (TSS)\n",
    "    total_variance = torch.sum((y_true - y_true_mean) ** 2, dim=0)\n",
    "\n",
    "    # Residual sum of squares (RSS)\n",
    "    residuals = torch.sum((y_true - y_pred) ** 2, dim=0)\n",
    "\n",
    "    # To handle the case where total_variance is zero (i.e., constant target values),\n",
    "    # we use torch.where to define R² as 0 in these cases.\n",
    "    r2 = torch.where(total_variance != 0, 1 - (residuals / total_variance), torch.tensor(0.0, device=y_true.device))\n",
    "\n",
    "    return r2.mean()  # Mean R² across all channels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder for pts\n",
    "\n",
    "refs:\n",
    "https://github.com/guochengqian/pointnext\n",
    "https://github.com/Pointcept/PointTransformerV3\n",
    "https://github.com/wolny/pytorch-3dunet/blob/master/pytorch3dunet/unet3d/model.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### net - temporal s2 stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ref: https://github.com/icey-zhang/SuperYOLO/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S0924271624003502#fig1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion s2 data\n",
    "class SE_Block(nn.Module):\n",
    "    def __init__(self, ch_in, reduction=16):\n",
    "        super(SE_Block, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # 全局自适应池化\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(ch_in, ch_in // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(ch_in // reduction, ch_in, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c) # squeeze操作\n",
    "        y = self.fc(y).view(b, c, 1, 1) # FC获取通道注意力权重，是具有全局信息的\n",
    "        return x * y.expand_as(x) # 注意力作用每一个通道上\n",
    "    \n",
    "class MF(nn.Module):  # Multi-Feature (MF) module for seasonal attention-based fusion\n",
    "    def __init__(self, channels=13, reduction=16):  # Each season has 13 channels\n",
    "        super(MF, self).__init__()\n",
    "        # Channel attention for each season (spring, summer, autumn, winter)\n",
    "        self.channels=channels\n",
    "        self.reduction=reduction\n",
    "        self.mask_map_spring = nn.Conv2d(self.channels, 1, 1, 1, 0, bias=True)\n",
    "        self.mask_map_summer = nn.Conv2d(self.channels, 1, 1, 1, 0, bias=True)\n",
    "        self.mask_map_autumn = nn.Conv2d(self.channels, 1, 1, 1, 0, bias=True)\n",
    "        self.mask_map_winter = nn.Conv2d(self.channels, 1, 1, 1, 0, bias=True)\n",
    "        \n",
    "        # Shared bottleneck layers for each season\n",
    "        self.bottleneck_spring = nn.Conv2d(self.channels, 16, 3, 1, 1, bias=False)\n",
    "        self.bottleneck_summer = nn.Conv2d(self.channels, 16, 3, 1, 1, bias=False)\n",
    "        self.bottleneck_autumn = nn.Conv2d(self.channels, 16, 3, 1, 1, bias=False)\n",
    "        self.bottleneck_winter = nn.Conv2d(self.channels, 16, 3, 1, 1, bias=False)\n",
    "        \n",
    "        # Final SE Block for channel attention across all seasons\n",
    "        self.se = SE_Block(64, self.reduction)  # Since we have 4 seasons with 16 channels each, we get a total of 64 channels\n",
    "\n",
    "    def forward(self, x):  # x is a list of 4 inputs (spring, summer, autumn, winter)\n",
    "        spring, summer, autumn, winter = x  # Unpack the inputs\n",
    "\n",
    "        # Apply attention maps\n",
    "        spring_mask = torch.mul(self.mask_map_spring(spring).repeat(1, self.channels, 1, 1), spring)\n",
    "        summer_mask = torch.mul(self.mask_map_summer(summer).repeat(1, self.channels, 1, 1), summer)\n",
    "        autumn_mask = torch.mul(self.mask_map_autumn(autumn).repeat(1, self.channels, 1, 1), autumn)\n",
    "        winter_mask = torch.mul(self.mask_map_winter(winter).repeat(1, self.channels, 1, 1), winter)\n",
    "\n",
    "        # Apply bottleneck layers\n",
    "        spring_features = self.bottleneck_spring(spring_mask)\n",
    "        summer_features = self.bottleneck_summer(summer_mask)\n",
    "        autumn_features = self.bottleneck_autumn(autumn_mask)\n",
    "        winter_features = self.bottleneck_winter(winter_mask)\n",
    "\n",
    "        # Concatenate features from all seasons\n",
    "        combined_features = torch.cat([spring_features, summer_features, autumn_features, winter_features], dim=1)\n",
    "\n",
    "        # Apply SE Block for channel-wise attention\n",
    "        out = self.se(combined_features)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)  # Adjust channel dimensions if necessary\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)  # Skip connection\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += identity  # Add skip connection to the output\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating UNet to incorporate residual connections and MF module\n",
    "class ResUNet_MF(pl.LightningModule):\n",
    "    def __init__(self, n_bands=13, out_channels=9, use_mf=False, use_residual=False, optimizer_type=\"adam\", learning_rate=1e-3, scheduler_type=None, scheduler_params=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_bands (int): Number of input channels (bands) for each season.\n",
    "            out_channels (int): Number of output channels.\n",
    "            use_mf (bool): Whether to use the MF module.\n",
    "            use_residual (bool): Whether to use Residual connections in U-Net blocks.\n",
    "            optimizer_type (str): Type of optimizer ('adam', 'sgd', etc.).\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            scheduler_type (str): Type of scheduler ('plateau', etc.).\n",
    "            scheduler_params (dict): Parameters for the scheduler (e.g., 'patience', 'factor' for ReduceLROnPlateau).\n",
    "        \"\"\"\n",
    "        super(ResUNet_MF, self).__init__()\n",
    "\n",
    "        self.use_mf = use_mf\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        if self.use_mf:\n",
    "            # MF Module for seasonal fusion (each season has `n_bands` channels)\n",
    "            self.mf_module = MF(channels=n_bands)\n",
    "            total_input_channels = 64  # MF module outputs 64 channels after processing four seasons\n",
    "        else:\n",
    "            total_input_channels = n_bands * 4  # If no MF module, concatenating all seasons directly\n",
    "\n",
    "        # Define the U-Net architecture with or without Residual connections\n",
    "        if self.use_residual:\n",
    "            self.enc_conv0 = ResidualBlock(total_input_channels, 64)\n",
    "            self.enc_conv1 = ResidualBlock(64, 128)\n",
    "            self.enc_conv2 = ResidualBlock(128, 256)\n",
    "            self.enc_conv3 = ResidualBlock(256, 512)\n",
    "            self.dec_conv3 = ResidualBlock(512, 256)\n",
    "            self.dec_conv2 = ResidualBlock(256, 128)\n",
    "            self.dec_conv1 = ResidualBlock(128, 64)\n",
    "        else:\n",
    "            self.enc_conv0 = nn.Conv2d(total_input_channels, 64, kernel_size=3, padding=1)\n",
    "            self.enc_conv1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.enc_conv2 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            self.enc_conv3 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "            self.dec_conv3 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "            self.dec_conv2 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "            self.dec_conv1 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec_conv0 = nn.Conv2d(64, out_channels, kernel_size=3, padding=1)  # Output layer\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Loss and learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = MaskedMSELoss()\n",
    "\n",
    "        # Optimizer and scheduler types\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.scheduler_type = scheduler_type\n",
    "        self.scheduler_params = scheduler_params if scheduler_params else {}\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Optionally pass inputs through MF module\n",
    "        if self.use_mf:\n",
    "            # Apply the MF module first to extract features from input\n",
    "            spring, summer, fall, winter = inputs  # Unpack the individual datasets\n",
    "            # Process through the MF module\n",
    "            fused_features = self.mf_module([spring, summer, fall, winter])\n",
    "        else:\n",
    "            # Concatenate all seasons directly if no MF module\n",
    "            fused_features = torch.cat(inputs, dim=1)\n",
    "\n",
    "        # U-Net forward pass (with or without residual connections)\n",
    "        x1 = F.relu(self.enc_conv0(fused_features))\n",
    "        x2 = self.pool(x1)\n",
    "        x2 = F.relu(self.enc_conv1(x2))\n",
    "        x3 = self.pool(x2)\n",
    "        x3 = F.relu(self.enc_conv2(x3))\n",
    "        x4 = self.pool(x3)\n",
    "        x4 = F.relu(self.enc_conv3(x4))\n",
    "\n",
    "        x = self.up(x4)\n",
    "        x = F.relu(self.dec_conv3(x))\n",
    "        x = self.up(x)\n",
    "        x = F.relu(self.dec_conv2(x))\n",
    "        x = self.up(x)\n",
    "        x = F.relu(self.dec_conv1(x))\n",
    "        x = self.dec_conv0(x)  # Output layer (no activation here)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def compute_loss_and_metrics(self, outputs, targets, masks, stage=\"val\"):\n",
    "        \"\"\"\n",
    "        Computes the masked loss, R² score, and logs the metrics.\n",
    "\n",
    "        Args:\n",
    "        - outputs: Predicted values (batch_size, num_channels, H, W)\n",
    "        - targets: Ground truth values (batch_size, num_channels, H, W)\n",
    "        - masks: Boolean mask indicating NoData pixels (batch_size, H, W)\n",
    "        - stage: One of 'train', 'val', or 'test', used for logging purposes.\n",
    "\n",
    "        Returns:\n",
    "        - loss: The computed masked loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Expand the mask to match the number of channels in outputs and targets\n",
    "        expanded_mask = masks.unsqueeze(1).expand_as(outputs)  # Shape: (batch_size, num_channels, H, W)\n",
    "\n",
    "        # Exclude NoData pixels by applying the mask (keep only valid pixels)\n",
    "        valid_outputs = outputs.masked_select(~expanded_mask).view(-1, outputs.size(1))\n",
    "        valid_targets = targets.masked_select(~expanded_mask).view(-1, targets.size(1))\n",
    "\n",
    "        # Compute the masked loss\n",
    "        loss = self.criterion(outputs, targets, masks)\n",
    "\n",
    "        # Calculate R² score for valid pixels\n",
    "        r2 = r2_score_torch(valid_targets, valid_outputs)\n",
    "\n",
    "        # Log the loss and R² score\n",
    "        self.log(f'{stage}_loss', loss, logger=True)\n",
    "        self.log(f'{stage}_r2', r2, logger=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets, masks = batch\n",
    "        outputs = self(inputs)  # Forward pass\n",
    "        \n",
    "        return self.compute_loss_and_metrics(outputs, targets, masks, stage=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets, masks = batch\n",
    "        outputs = self(inputs)  # Forward pass\n",
    "        \n",
    "        return self.compute_loss_and_metrics(outputs, targets, masks, stage=\"val\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets, masks = batch\n",
    "        outputs = self(inputs)  # Forward pass\n",
    "\n",
    "        return self.compute_loss_and_metrics(outputs, targets, masks, stage=\"test\")\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Choose the optimizer based on input parameter\n",
    "        if self.optimizer_type == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        elif self.optimizer_type == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer type: {self.optimizer_type}\")\n",
    "\n",
    "        # Configure the scheduler based on the input parameter\n",
    "        if self.scheduler_type == \"plateau\":\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, **self.scheduler_params\n",
    "            )\n",
    "            return {\n",
    "                'optimizer': optimizer,\n",
    "                'lr_scheduler': {\n",
    "                    'scheduler': scheduler,\n",
    "                    'monitor': 'val_loss',  # Reduce learning rate when 'val_loss' plateaus\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSpeciesDataset(Dataset):\n",
    "    def __init__(self, tile_names, processed_dir, datasets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_names (list): List of tile filenames to load.\n",
    "            processed_dir (str): Base directory containing the processed data folders.\n",
    "            datasets (list): List of dataset folder names to include (e.g., ['s2/spring', 's2/summer', 'topo', 'climate']).\n",
    "        \"\"\"\n",
    "        self.tile_names = tile_names\n",
    "        self.processed_dir = processed_dir\n",
    "        self.datasets = datasets  # List of dataset folder names\n",
    "        \n",
    "        # Calculate number of bands by inspecting the first tile of the first dataset\n",
    "        example_file = os.path.join(self.processed_dir, datasets[0], tile_names[0])\n",
    "        with rasterio.open(example_file) as src:\n",
    "            self.n_bands = src.count\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tile_name = self.tile_names[idx]\n",
    "        input_data_list = []\n",
    "\n",
    "        # Load data from each dataset (spring, summer, fall, winter, etc.)\n",
    "        for dataset in self.datasets:\n",
    "            dataset_path = os.path.join(self.processed_dir, dataset, tile_name)\n",
    "            with rasterio.open(dataset_path) as src:\n",
    "                input_data = src.read()  # Read the bands (num_bands, H, W)\n",
    "                input_data_list.append(torch.from_numpy(input_data).float())  # Append each season's tensor to the list\n",
    "\n",
    "        # Load the corresponding label (target species composition)\n",
    "        label_path = os.path.join(self.processed_dir, 'labels/tiles_128', tile_name)\n",
    "        \n",
    "        with rasterio.open(label_path) as src:\n",
    "            target_data = src.read()  # (num_bands, H, W)\n",
    "            nodata_value_label = src.nodata  # NoData value for the labels\n",
    "\n",
    "            # Create a NoData mask for the target data\n",
    "            if nodata_value_label is not None:\n",
    "                mask = np.any(target_data == nodata_value_label, axis=0)  # Collapse bands to (H, W)\n",
    "            else:\n",
    "                mask = np.zeros_like(target_data[0], dtype=bool)  # Assume all valid if no NoData value\n",
    "\n",
    "        # Convert the target and mask to PyTorch tensors\n",
    "        target_tensor = torch.from_numpy(target_data).float()  # Shape: (num_output_channels, H, W)\n",
    "        mask_tensor = torch.from_numpy(mask).bool()  # Shape: (H, W)\n",
    "\n",
    "        # Return the list of input tensors for each season, the target tensor, and the mask tensor\n",
    "        return input_data_list, target_tensor, mask_tensor\n",
    "\n",
    "class TreeSpeciesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, tile_names, processed_dir, datasets_to_use, batch_size=4, num_workers=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_names (dict): Dictionary with 'train', 'val', and 'test' keys containing lists of tile filenames to load.\n",
    "            processed_dir (str): Directory where processed data is located.\n",
    "            datasets_to_use (list): List of dataset names to include (e.g., ['s2/spring', 's2/summer', ...]).\n",
    "            batch_size (int): Batch size for DataLoader.\n",
    "            num_workers (int): Number of workers for DataLoader.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tile_names = tile_names\n",
    "        self.processed_dir = processed_dir\n",
    "        self.datasets_to_use = datasets_to_use\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Sets up the dataset for train, validation, and test splits.\n",
    "        \"\"\"\n",
    "        # Create datasets for train, validation, and test\n",
    "        self.train_dataset = TreeSpeciesDataset(self.tile_names['train'], self.processed_dir, self.datasets_to_use)\n",
    "        self.val_dataset = TreeSpeciesDataset(self.tile_names['val'], self.processed_dir, self.datasets_to_use)\n",
    "        self.test_dataset = TreeSpeciesDataset(self.tile_names['test'], self.processed_dir, self.datasets_to_use)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tile_names(file_path):\n",
    "    \"\"\"\n",
    "    Load tile names from a .txt file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .txt file.\n",
    "\n",
    "    Returns:\n",
    "        tile_names (list): List of tile names.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        tile_names = f.read().splitlines()\n",
    "    return tile_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datasets_to_use, resolution, log_name, num_epoch=10, use_mf=True, use_residual=True):\n",
    "    wandb.init()\n",
    "    # Tile names for train, validation, and test\n",
    "    tile_names = {\n",
    "        'train': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/train_tiles.txt'),\n",
    "        'val': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/val_tiles.txt'),\n",
    "        'test': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/test_tiles.txt')\n",
    "    }\n",
    "    # Initialize the DataModule\n",
    "    data_module = TreeSpeciesDataModule(\n",
    "        tile_names=tile_names,\n",
    "        processed_dir=f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m',  # Base directory where the datasets are stored\n",
    "        datasets_to_use=datasets_to_use,\n",
    "        batch_size=8,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Call setup explicitly to initialize datasets\n",
    "    data_module.setup(stage='fit')\n",
    "    # Access `n_bands` after the dataset has been initialized\n",
    "    n_bands = data_module.train_dataset.n_bands\n",
    "    \n",
    "    # Use the calculated input channels from the DataModule to initialize the model\n",
    "    model = ResUNet_MF(\n",
    "        n_bands=n_bands,  # Example channel config\n",
    "        out_channels=9,\n",
    "        use_mf=use_mf,\n",
    "        use_residual=use_residual,\n",
    "        optimizer_type=\"adam\",\n",
    "        learning_rate=1e-3,\n",
    "        scheduler_type=\"plateau\",\n",
    "        scheduler_params={'patience': 3, 'factor': 0.5}\n",
    "    )\n",
    "\n",
    "    # Define a checkpoint callback to save the best model\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',  # Track the validation loss\n",
    "        filename='best-model-{epoch:02d}-{val_loss:.2f}',\n",
    "        save_top_k=1,  # Only save the best model\n",
    "        mode='min'  # We want to minimize the validation loss\n",
    "    )\n",
    "\n",
    "    csv_logger = CSVLogger(save_dir='logs/csv_logs', name=log_name)\n",
    "    wandb_logger = WandbLogger(name=log_name, save_dir='logs/wandb_logs', offline=True)\n",
    "    \n",
    "    # Create a PyTorch Lightning Trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=num_epoch,\n",
    "        logger=[wandb_logger, csv_logger],\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    wandb_logger.log_text('parameters.txt', dataframe=pd.DataFrame({'datasets': [datasets_to_use], 'num_epoches': num_epoch, 'resolution': resolution}))\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # Test the model after training\n",
    "    trainer.test(model, data_module)\n",
    "\n",
    "    # Save the best model after training\n",
    "    trainer.save_checkpoint(f\"logs/checkpoints/{log_name}/final_model.pt\")\n",
    "    # Load the saved model\n",
    "    #model = UNetLightning.load_from_checkpoint(\"final_model.ckpt\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.\n"
     ]
    }
   ],
   "source": [
    "!wandb offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | Conv2d        | 20.8 K | train\n",
      "1  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "2  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "3  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "4  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "6  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.496    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:  75%|███████▌  | 140/186 [00:27<00:09,  5.06it/s, v_num=fa_1, train_r2=0.440, val_r2=0.375]    "
     ]
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, 'Uet_S4', num_epoch=200, use_mf=False, use_residual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# User specifies which datasets to use\u001b[39;00m\n\u001b[1;32m      2\u001b[0m datasets_to_use \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmf_s2/spring/tiles_128\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmf_s2/summer/tiles_128\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmf_s2/fall/tiles_128\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmf_s2/winter/tiles_128\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m(datasets_to_use, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUet_S4_10m\u001b[39m\u001b[38;5;124m'\u001b[39m, num_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, use_mf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_residual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10, 'Uet_S4_10m', num_epoch=200, use_mf=False, use_residual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | enc_conv0 | ResidualBlock | 60.1 K | train\n",
      "1  | enc_conv1 | ResidualBlock | 229 K  | train\n",
      "2  | enc_conv2 | ResidualBlock | 918 K  | train\n",
      "3  | enc_conv3 | ResidualBlock | 3.7 M  | train\n",
      "4  | dec_conv3 | ResidualBlock | 1.9 M  | train\n",
      "5  | dec_conv2 | ResidualBlock | 475 K  | train\n",
      "6  | dec_conv1 | ResidualBlock | 118 K  | train\n",
      "7  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "8  | pool      | MaxPool2d     | 0      | train\n",
      "9  | up        | Upsample      | 0      | train\n",
      "10 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "7.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 M     Total params\n",
      "29.523    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 186/186 [00:50<00:00,  3.71it/s, v_num=ec_0, train_r2=0.865, val_r2=0.516] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 186/186 [00:50<00:00,  3.71it/s, v_num=ec_0, train_r2=0.865, val_r2=0.516]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.024757172912359238    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5483073592185974     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.024757172912359238   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5483073592185974    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▅▆█▅▇▆▅▃▃▂▂▂▂▂▂▂▂▃▃▁▂▁▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>train_r2</td><td>▁▃▃▆▆▆▆▆▅▆▇▆▇█▇▆▇██▇██▇██▇▇▇▇▇▇█▇▇▇▇▇▇██</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▄▄▃▂▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_r2</td><td>▁▄▂▇▇▅▁███▇▇█▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>test_loss</td><td>0.02476</td></tr><tr><td>test_r2</td><td>0.54831</td></tr><tr><td>train_loss</td><td>0.00687</td></tr><tr><td>train_r2</td><td>0.86455</td></tr><tr><td>trainer/global_step</td><td>18600</td></tr><tr><td>val_loss</td><td>0.02647</td></tr><tr><td>val_r2</td><td>0.51639</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20241008_124652-hcu0n6ec<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241008_124652-hcu0n6ec/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, 'RUet_S4', num_epoch=200, use_mf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10, 'RUet_S4_10m', num_epoch=200, use_mf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | mf_module | MF            | 5.7 K  | train\n",
      "1  | enc_conv0 | Conv2d        | 36.9 K | train\n",
      "2  | enc_conv1 | Conv2d        | 73.9 K | train\n",
      "3  | enc_conv2 | Conv2d        | 295 K  | train\n",
      "4  | enc_conv3 | Conv2d        | 1.2 M  | train\n",
      "5  | dec_conv3 | Conv2d        | 1.2 M  | train\n",
      "6  | dec_conv2 | Conv2d        | 295 K  | train\n",
      "7  | dec_conv1 | Conv2d        | 73.8 K | train\n",
      "8  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "9  | pool      | MaxPool2d     | 0      | train\n",
      "10 | up        | Upsample      | 0      | train\n",
      "11 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.583    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  39%|███▊      | 72/186 [00:16<00:25,  4.45it/s, v_num=ny_5, train_r2=-0.902]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09816724807024002    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -0.7892652153968811    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09816724807024002   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -0.7892652153968811   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>train_r2</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_loss</td><td>0.09817</td></tr><tr><td>test_r2</td><td>-0.78927</td></tr><tr><td>train_loss</td><td>0.12196</td></tr><tr><td>train_r2</td><td>-0.89027</td></tr><tr><td>trainer/global_step</td><td>72</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20241008_190827-rg1vtcny<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241008_190827-rg1vtcny/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, 'Uet_S4_MF', num_epoch=200, use_residual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 10, 'Uet_S4_10m_MF', num_epoch=200, use_residual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:mtgm8goa) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20241008_105130-mtgm8goa<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241008_105130-mtgm8goa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:mtgm8goa). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type          | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0  | mf_module | MF            | 5.7 K  | train\n",
      "1  | enc_conv0 | ResidualBlock | 78.0 K | train\n",
      "2  | enc_conv1 | ResidualBlock | 229 K  | train\n",
      "3  | enc_conv2 | ResidualBlock | 918 K  | train\n",
      "4  | enc_conv3 | ResidualBlock | 3.7 M  | train\n",
      "5  | dec_conv3 | ResidualBlock | 1.9 M  | train\n",
      "6  | dec_conv2 | ResidualBlock | 475 K  | train\n",
      "7  | dec_conv1 | ResidualBlock | 118 K  | train\n",
      "8  | dec_conv0 | Conv2d        | 5.2 K  | train\n",
      "9  | pool      | MaxPool2d     | 0      | train\n",
      "10 | up        | Upsample      | 0      | train\n",
      "11 | criterion | MaskedMSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "7.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 M     Total params\n",
      "29.617    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 186/186 [00:52<00:00,  3.57it/s, v_num=8b_3, train_r2=0.546, val_r2=0.348]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 186/186 [00:52<00:00,  3.52it/s, v_num=8b_3, train_r2=0.546, val_r2=0.348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:08<00:00,  4.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03299941495060921    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37007516622543335    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03299941495060921   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37007516622543335   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_r2</td><td>▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_r2</td><td>▁▆██████████████████████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_r2</td><td>▁▆██████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>test_loss</td><td>0.033</td></tr><tr><td>test_r2</td><td>0.37008</td></tr><tr><td>train_loss</td><td>0.02325</td></tr><tr><td>train_r2</td><td>0.54649</td></tr><tr><td>trainer/global_step</td><td>18600</td></tr><tr><td>val_loss</td><td>0.03478</td></tr><tr><td>val_r2</td><td>0.34807</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/d/Sync/research/tree_species_estimation/code/fusion/M3F_Net/wandb/offline-run-20241008_105635-jxwln18b<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241008_105635-jxwln18b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User specifies which datasets to use\n",
    "datasets_to_use = ['rmf_s2/spring/tiles_128','rmf_s2/summer/tiles_128','rmf_s2/fall/tiles_128','rmf_s2/winter/tiles_128']\n",
    "\n",
    "train(datasets_to_use, 20, 'RUet_S4_MF', num_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pts stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import torch\n",
    "import rasterio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class TreeSpeciesPointCloudDataset(Dataset):\n",
    "    def __init__(self, tile_names, processed_dir, datasets, point_cloud_dir, imagery=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_names (list): List of tile filenames to load.\n",
    "            processed_dir (str): Base directory containing the processed imagery data.\n",
    "            datasets (list): List of dataset folder names to include (e.g., ['s2/spring', 's2/summer']).\n",
    "            point_cloud_dir (str): Directory containing point clouds in .laz format.\n",
    "            imagery (bool): Whether to load imagery data. If False, only point clouds are loaded.\n",
    "        \"\"\"\n",
    "        self.tile_names = tile_names\n",
    "        self.processed_dir = processed_dir\n",
    "        self.datasets = datasets  # List of dataset folder names\n",
    "        self.point_cloud_dir = point_cloud_dir  # Directory for point clouds\n",
    "        self.imagery = imagery\n",
    "\n",
    "        # If imagery is to be loaded, calculate number of bands\n",
    "        if self.imagery:\n",
    "            example_file = os.path.join(self.processed_dir, datasets[0], tile_names[0])\n",
    "            with rasterio.open(example_file) as src:\n",
    "                self.n_bands = src.count\n",
    "        else:\n",
    "            self.n_bands = None  # Imagery is not being loaded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_names)\n",
    "\n",
    "    def _load_point_cloud(self, tile_name, row_idx, col_idx):\n",
    "        \"\"\"\n",
    "        Load and filter the point cloud for the given tile_name, row_idx, and col_idx.\n",
    "        Filter out points where classification == 0.\n",
    "        If all points are invalid, return a dummy point cloud.\n",
    "        \"\"\"\n",
    "        point_cloud_file = os.path.join(self.point_cloud_dir, f\"{tile_name}_{row_idx}_{col_idx}.laz\")\n",
    "\n",
    "        # Use laspy to read the .laz file\n",
    "        with laspy.open(point_cloud_file) as f:\n",
    "            point_cloud = f.read()\n",
    "\n",
    "        # Extract points and filter out points where classification == 0 (invalid points)\n",
    "        valid_mask = point_cloud.classification != 0  # Valid points have classification != 0\n",
    "\n",
    "        if valid_mask.sum() > 0:  # Check if there are any valid points\n",
    "            points = np.vstack([point_cloud.x[valid_mask], point_cloud.y[valid_mask], point_cloud.z[valid_mask]]).T\n",
    "        else:\n",
    "            # If no valid points, return a dummy point cloud (e.g., all zeros)\n",
    "            points = np.zeros((1, 3))  # Assuming 3D point cloud (x, y, z)\n",
    "\n",
    "        return torch.from_numpy(points).float(), valid_mask\n",
    "\n",
    "    def _load_imagery(self, tile_name):\n",
    "        \"\"\"\n",
    "        Load the imagery for the given tile_name and create a NoData mask.\n",
    "        \"\"\"\n",
    "        input_data_list = []\n",
    "\n",
    "        # Load data from each dataset (spring, summer, fall, winter, etc.)\n",
    "        for dataset in self.datasets:\n",
    "            dataset_path = os.path.join(self.processed_dir, dataset, tile_name)\n",
    "            with rasterio.open(dataset_path) as src:\n",
    "                input_data = src.read()  # Read the bands (num_bands, H, W)\n",
    "                nodata_value = src.nodata\n",
    "\n",
    "                # Create a NoData mask for the imagery\n",
    "                if nodata_value is not None:\n",
    "                    mask = np.any(input_data == nodata_value, axis=0)  # Collapse bands to (H, W)\n",
    "                else:\n",
    "                    mask = np.zeros_like(input_data[0], dtype=bool)  # Assume all valid if no NoData value\n",
    "\n",
    "                input_data_list.append(torch.from_numpy(input_data).float())  # Append each season's tensor to the list\n",
    "\n",
    "        # Combine masks from all datasets\n",
    "        combined_imagery_mask = torch.from_numpy(mask).bool()\n",
    "\n",
    "        return input_data_list, combined_imagery_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tile_name = self.tile_names[idx]\n",
    "\n",
    "        # Load imagery data if requested\n",
    "        if self.imagery:\n",
    "            input_data_list, imagery_mask = self._load_imagery(tile_name)\n",
    "        else:\n",
    "            imagery_mask = None  # No imagery mask\n",
    "\n",
    "        # Load the corresponding label (target species composition)\n",
    "        label_path = os.path.join(self.processed_dir, 'labels/tiles_128', tile_name)\n",
    "        with rasterio.open(label_path) as src:\n",
    "            target_data = src.read()  # (num_bands, H, W)\n",
    "            nodata_value_label = src.nodata  # NoData value for the labels\n",
    "\n",
    "            # Create a NoData mask for the labels\n",
    "            if nodata_value_label is not None:\n",
    "                label_mask = np.any(target_data == nodata_value_label, axis=0)  # Collapse bands to (H, W)\n",
    "            else:\n",
    "                label_mask = np.zeros_like(target_data[0], dtype=bool)  # Assume all valid if no NoData value\n",
    "\n",
    "        # Initialize the combined mask (start with label mask)\n",
    "        combined_mask = torch.from_numpy(label_mask).bool()\n",
    "\n",
    "        # If imagery is loaded, combine imagery mask with label mask\n",
    "        if self.imagery:\n",
    "            combined_mask = combined_mask | imagery_mask\n",
    "\n",
    "        # Load point clouds for each pixel in the tile and update the combined mask\n",
    "        if self.imagery:\n",
    "            H, W = input_data_list[0].shape[1], input_data_list[0].shape[2]  # Get the height and width of the tile\n",
    "        else:\n",
    "            # If imagery is not loaded, we need to determine H and W from the labels\n",
    "            H, W = target_data.shape[1], target_data.shape[2]\n",
    "\n",
    "        point_clouds = []\n",
    "\n",
    "        for row_idx in range(H):\n",
    "            for col_idx in range(W):\n",
    "                if not combined_mask[row_idx, col_idx]:  # If pixel is valid\n",
    "                    point_cloud, valid_pc_mask = self._load_point_cloud(tile_name, row_idx, col_idx)\n",
    "\n",
    "                    # If the point cloud is invalid (classification == 0), update combined mask\n",
    "                    if point_cloud.size(0) > 0 and valid_pc_mask.sum() > 0:  # Ensure point cloud is valid\n",
    "                        point_clouds.append(point_cloud)\n",
    "                    else:\n",
    "                        combined_mask[row_idx, col_idx] = True  # Mark as invalid in the combined mask\n",
    "                        point_clouds.append(torch.zeros((1, 3)))  # Append a dummy point cloud\n",
    "                else:\n",
    "                    point_clouds.append(torch.zeros((1, 3)))  # Append a dummy point cloud for invalid pixels\n",
    "\n",
    "        # Convert the list of point clouds to a tensor (H * W, num_points, point_features)\n",
    "        point_clouds_tensor = torch.stack(point_clouds).float()  # Shape: (H * W, num_points, point_features)\n",
    "\n",
    "        # Convert the target and mask to PyTorch tensors\n",
    "        target_tensor = torch.from_numpy(target_data).float()  # Shape: (num_output_channels, H, W)\n",
    "\n",
    "        # Return the data according to whether imagery is loaded\n",
    "        if self.imagery:\n",
    "            return input_data_list, point_clouds_tensor, target_tensor, combined_mask\n",
    "        else:\n",
    "            return point_clouds_tensor, target_tensor, combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSpeciesPointCloudDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, tile_names, processed_dir, datasets_to_use, point_cloud_dir, imagery=True, batch_size=4, num_workers=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_names (dict): Dictionary with 'train', 'val', and 'test' keys containing lists of tile filenames to load.\n",
    "            processed_dir (str): Directory where processed data is located.\n",
    "            datasets_to_use (list): List of dataset names to include (e.g., ['s2/spring', 's2/summer']).\n",
    "            point_cloud_dir (str): Directory containing point cloud data in .laz format.\n",
    "            imagery (bool): Whether to load imagery data. If False, only point clouds are loaded.\n",
    "            batch_size (int): Batch size for DataLoader.\n",
    "            num_workers (int): Number of workers for DataLoader.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tile_names = tile_names\n",
    "        self.processed_dir = processed_dir\n",
    "        self.datasets_to_use = datasets_to_use\n",
    "        self.point_cloud_dir = point_cloud_dir\n",
    "        self.imagery = imagery\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Sets up the dataset for train, validation, and test splits.\n",
    "        \"\"\"\n",
    "        # Create datasets for train, validation, and test\n",
    "        self.train_dataset = TreeSpeciesPointCloudDataset(\n",
    "            self.tile_names['train'],\n",
    "            self.processed_dir,\n",
    "            self.datasets_to_use,\n",
    "            self.point_cloud_dir,\n",
    "            imagery=self.imagery\n",
    "        )\n",
    "        self.val_dataset = TreeSpeciesPointCloudDataset(\n",
    "            self.tile_names['val'],\n",
    "            self.processed_dir,\n",
    "            self.datasets_to_use,\n",
    "            self.point_cloud_dir,\n",
    "            imagery=self.imagery\n",
    "        )\n",
    "        self.test_dataset = TreeSpeciesPointCloudDataset(\n",
    "            self.tile_names['test'],\n",
    "            self.processed_dir,\n",
    "            self.datasets_to_use,\n",
    "            self.point_cloud_dir,\n",
    "            imagery=self.imagery\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PointNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from pointnext import PointNext, PointNextDecoder, pointnext_s\n",
    "\n",
    "class PointNeXtLightning(pl.LightningModule):\n",
    "    def __init__(self, num_classes=9, learning_rate=1e-3):\n",
    "        super(PointNeXtLightning, self).__init__()\n",
    "        \n",
    "        # Load PointNeXt backbone from torch-points3d\n",
    "        encoder = pointnext_s(in_dim=3)\n",
    "        self.pointnext = PointNext(num_classes, encoder=encoder, decoder=PointNextDecoder(encoder_dims=encoder.encoder_dims))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            point_cloud: Input point cloud tensor (B, N, 3), where:\n",
    "            B = Batch size, N = Number of points, 3 = (x, y, z) coordinates\n",
    "        \n",
    "        Returns:\n",
    "            logits: Class logits for each point (B, N, num_classes)\n",
    "        \"\"\"\n",
    "        return self.pointnext(point_cloud)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        point_clouds, targets, mask = batch\n",
    "        outputs = self(point_clouds)  # Forward pass\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.criterion(outputs, targets.long())\n",
    "        \n",
    "        # Log training loss\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        point_clouds, targets, mask = batch\n",
    "        outputs = self(point_clouds)  # Forward pass\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.criterion(outputs, targets.long())\n",
    "        \n",
    "        # Log validation loss\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # Example scheduler\n",
    "        \n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuwei-linux/code/venv/lib/python3.10/site-packages/pointnext/ops.py:118: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from pointnext import PointNext, PointNextDecoder, pointnext_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(datasets_to_use, resolution, log_name, num_epoch=10, use_mf=True, use_residual=True):\n",
    "    wandb.init()\n",
    "    # Tile names for train, validation, and test\n",
    "    tile_names = {\n",
    "        'train': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/train_tiles.txt'),\n",
    "        'val': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/val_tiles.txt'),\n",
    "        'test': load_tile_names(f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m/dataset/test_tiles.txt')\n",
    "    }\n",
    "    # Instantiate data module (imagery=False to only load point clouds)\n",
    "    data_module = TreeSpeciesPointCloudDataModule(\n",
    "        tile_names=tile_names,\n",
    "        processed_dir=f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m',\n",
    "        datasets_to_use=[],  # No need for imagery datasets\n",
    "        point_cloud_dir=f'/mnt/g/rmf/m3f_spl/laz_plots',\n",
    "        imagery=False,  # Only point cloud\n",
    "        batch_size=8,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = PointNeXtLightning(num_classes=9, learning_rate=1e-3)\n",
    "\n",
    "    # Define a checkpoint callback to save the best model\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',  # Track the validation loss\n",
    "        filename='best-model-{epoch:02d}-{val_loss:.2f}',\n",
    "        save_top_k=1,  # Only save the best model\n",
    "        mode='min'  # We want to minimize the validation loss\n",
    "    )\n",
    "\n",
    "    csv_logger = CSVLogger(save_dir='logs/csv_logs', name=log_name)\n",
    "    wandb_logger = WandbLogger(name=log_name, save_dir='logs/wandb_logs', offline=True)\n",
    "    \n",
    "    # Create a PyTorch Lightning Trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=num_epoch,\n",
    "        logger=[wandb_logger, csv_logger],\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    wandb_logger.log_text('parameters.txt', dataframe=pd.DataFrame({'datasets': [datasets_to_use], 'num_epoches': num_epoch, 'resolution': resolution}))\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # Test the model after training\n",
    "    trainer.test(model, data_module)\n",
    "\n",
    "    # Save the best model after training\n",
    "    trainer.save_checkpoint(f\"logs/checkpoints/{log_name}/final_model.pt\")\n",
    "    # Load the saved model\n",
    "    #model = UNetLightning.load_from_checkpoint(\"final_model.ckpt\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = TreeSpeciesPointCloudDataModule(\n",
    "    tile_names=tile_names,\n",
    "    processed_dir=f'/mnt/d/Sync/research/tree_species_estimation/tree_dataset/rmf/processed/{resolution}m',\n",
    "    datasets_to_use=[],  # No need for imagery datasets\n",
    "    point_cloud_dir=f'/mnt/g/rmf/m3f_spl/laz_plots',\n",
    "    imagery=True,  # Load imagery\n",
    "    batch_size=4,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
